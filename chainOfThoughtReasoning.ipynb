{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# bigger the models are, they tend to be better at reasoning also the models that have been fine tuned from or have a large amount of code in pretraining tend to be good at reasoning sort of tasks\n",
    "llm = OpenAI(model_name = \"gpt-4\",\n",
    "             temperature = 0,\n",
    "             max_tokens = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, as we saw the way of thinking is correct but it does not provide the correct answer to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text  =\"Explain step by step. How old is the president of the United States\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to direct answer from llm without explaining step by step, it will give the answer.\n",
    "\n",
    "\n",
    "Anything it gives after the answer is going to be reinforcement or a justification of the answer that it gave there. This is not what we always want. Also this is one reason why we get hallucinations a lot because if it gives an answer, it then feels it has to justify that answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"How would I get from Sigapore to San Francisco?\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic sort of chain of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Explain step by step. How would I get from Singapore to San Francisco?\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve on this chain of thought  ReAct is going to be using both reasoning and actions. ReAct using the tools, but lets see how the manual ReAct works. Go to manualReact.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
